---
title: Webscraper from Windows 10 to Ubuntu
author: Chuck Horgan
date: '2022-06-21'
slug: []
categories: []
tags: []
description: ~
publishDate: '2022-06-21T17:03:00-04:00'
---

**:construction: under construction :construction:**

# Overview

I had written a web scraper in R to obtain information on daily [DoD Awards](https://www.defense.gov/Newsroom/Contracts/). The script does two main things:

1. Scrapes the most recent day's announcements and saves them in a tidy Excel file.

2. Sends an email to a recipient at CADE with the scraped data.

Naively, I scheduled the script to run daily through `taskscheduleR`, an R package that uses the Windows task manager to schedule jobs. However, when the COVID-19 pandemic hit and we shifted to working from home, I realized that the scraper wasn't running when my laptop wasn't on. As a temporary fix, I moved everything to a shared, remote Windows machine. I knew this was not the "right" way to do it, as it would not run if someone else was using a Remote Desktop Connection on the machine. Another issue was random Outlook updates requiring the manual input of credentials again.

So, this wiki documents the process of shifting everything to an Ubuntu 18.04 VM. Since many different things were involved in set up and configuration, the methods outlined below may be of use to someone else in the future, even if the goal is wildly different.

# Server Set Up

- Set up a Remote Desktop Protocol on the Ubuntu VM. This is quite a process in itself, so please see the following link to another page: [Setting up a Remote Desktop Connection on Ubuntu 18.04](Setting-up-a-Remote-Desktop-Connection-on-Ubuntu-18.04)

- Install R/RStudio. Again, quite a process, so see this page: [Installing and Configuring RStudio Desktop on Ubuntu 18.04](Installing-and-Configuring-RStudio-Desktop-on-Ubuntu-18.04)

- Set up a mail server. You guessed it, quite a process: [Installing and Configuring a Mail server on Ubuntu 18.04](Installing-and-Configuring-a-Mail-server-on-Ubuntu-18.04)

# Clone Project

- Clone from Git from within RStudio.

  - Go to File > New Project.

  - Select Version Control, then Git.

  - Copy/Paste the URL of the project's homepage on our GitLab.

  - Choose the correct directory for the project. I like to use one in my home directory named "GitLocal".

  - Click Create Project.

  - You may need to enter your GitLab credentials.

- We need to install Ubuntu dependencies to install `rvest` R package.

```
sudo apt-get install libcurl4-openssl-dev libxml2-dev
```

# Update Script

- Change all directory and file paths. Use relative instead of absolute, since the shell script will take care of the project directory.

- Delete section that sent email in R. This will be handled with the mail server we just set up on the Ubuntu VM.

- `openxlsx` actually works in Ubuntu, even if you can't open the Excel files. Not sure why this works, but it allows us to use a template that was cloned with the project. The template allows for formatted column widths and pretty headers.

- Write a couple run-specific variables to the project directory. These will be used in the email subject line and body.

```R
# write to .txt file for use with email message body
cat(as.character(page_contract_details$url), file = "scraped_url.txt")

# write to .txt file for use with email subject line
cat(as.character(page_date_extract), file = "scrape_date.txt")
```

# Create Shell Script

- This shell script will need to run the R script, save over the local extracted info file, and send an email with mutt.

- As of November 2020, it was as follows (remember, the current .sh file is in the repo linked at the top of this Page):

```
#!/bin/

# change to project directory
PROJ_DIR=/home/chorgan/GitLocal/dod-daily-contract-scraper
cd $PROJ_DIR

# print date for log info
echo `date`

# run R script that saves the updated information in the PROJ_DIR
Rscript dod_web_scraper.R

# prepare variables for email
DATE_SCRAPED=`cat scrape_date.txt`

TO="senser@technomics.net sandra.b.enser.ctr@mail.mil"
CC="chorgan@technomics.net"
SUBJECT="DoD Award Announcements for $DATE_SCRAPED"
SCRAPED_FILE=daily_award_info.xlsx
MESSAGE=`cat message.txt && cat scraped_url.txt`

# send email
echo $MESSAGE | mutt -s "$SUBJECT" -c $CC -a $SCRAPED_FILE -- $TO
```

# Schedule the Daily Job

- We will be using [cron](https://www.digitalocean.com/community/tutorials/how-to-use-cron-to-automate-tasks-ubuntu-1804) to schedule this task, as it is the most widely-used task-scheduler in the Linux world. Read up on how cron works in that hyperlink.

- Most distros come with cron, but to install it, do the following:

```
sudo apt-get update
sudo apt-get install cron
# enable the service
sudo systemctl enable cron
```

- Since we likely want to schedule tasks in our local timezone, ensure it is set correctly on our Ubuntu VM. [Setting timezone in Ubuntu](https://help.ubuntu.com/community/UbuntuTime)

```
# set timezone on server
sudo dpkg-reconfigure tzdata
# go through on-screen prompts

# restart cron service for changes to take effect
sudo service cron restart
```

- Edit your crontab to schedule the shell script. A good practice with scheduled tasks is piping the output to a log file. That way, we can always look back to see why something failed.

```
crontab -e
# the first time you edit your crontab, you will be asked for an editor of choice
# unless you have strong convictions, stick with nano (the default)

# add the following line to the end of your crontab to run the shell script every day at 10am
0 10 * * * cd ~/GitLocal/dod-daily-contract-scraper/ && sh scrape_DoD_contracts.sh > scrape_DoD_contracts.log
# note the pipe into a log file
```
